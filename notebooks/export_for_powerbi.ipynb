{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f0cbf-e98f-48c7-9f5f-464c29a0cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and cleaning data...\n",
      "Features used: ['neighbourhood_group', 'room_type', 'latitude', 'longitude', 'calculated_host_listings_count', 'availability_365', 'amenities_count', 'reviews_log', 'nights_log']\n",
      "Training rows: 3922, Test rows: 981\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sh_m_\\AppData\\Local\\Temp\\ipykernel_21332\\2468008277.py:78: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['reviews_per_month'].fillna(0, inplace=True)\n",
      "C:\\Users\\sh_m_\\AppData\\Local\\Temp\\ipykernel_21332\\2468008277.py:84: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to xgb_model.joblib and meta to preprocess_meta.joblib\n",
      "Creating final export CSV with predictions...\n",
      "Wrote final dataset to Airbnb_PowerBI_Final_Dataset.csv (4903 rows)\n",
      "Creating prediction grid for Power BI (slider)...\n",
      "Grid will have 13,950 rows (room_type * neighbourhood * min_nights * amenities_count)\n",
      "Wrote prediction grid to price_suggestion_grid.csv (13950 rows)\n",
      "All done. Files created:\n",
      " - Airbnb_PowerBI_Final_Dataset.csv\n",
      " - price_suggestion_grid.csv\n",
      " - xgb_model.joblib\n",
      " - preprocess_meta.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from joblib import dump\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "DATA_IN = \"New_York_Airbnb_Enhanced_Unclean.csv\"\n",
    "OUT_FINAL = \"Airbnb_PowerBI_Final_Dataset.csv\"\n",
    "OUT_GRID = \"price_suggestion_grid.csv\"\n",
    "\n",
    "# -------------------------\n",
    "# Helper preprocessing\n",
    "# -------------------------\n",
    "def count_amenities(x):\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    # amenities are often stored like: \"{'Wifi','TV',...}\" or '[\"Wifi\",\"TV\"]'\n",
    "    try:\n",
    "        # handle both python-list-like and quoted lists\n",
    "        val = ast.literal_eval(x)\n",
    "        if isinstance(val, (list, set, tuple)):\n",
    "            return len(val)\n",
    "        if isinstance(val, dict):\n",
    "            return len(val)\n",
    "    except Exception:\n",
    "        # fallback: count commas inside string (cheap heuristic)\n",
    "        try:\n",
    "            s = str(x)\n",
    "            return max(0, s.count(\",\") + 1)\n",
    "        except:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "def load_and_clean(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Keep a copy of original few columns if desired\n",
    "    # Remove rows with missing price or price <= 0\n",
    "    df = df[df['price'].notna()]\n",
    "    df = df[df['price'] > 0]\n",
    "\n",
    "    # Remove extreme outliers in price (cap at 99th percentile and/or absolute threshold)\n",
    "    pct99 = df['price'].quantile(0.99)\n",
    "    df = df[df['price'] <= min(pct99, 500)]  # limit to 500 or 99th percentile\n",
    "\n",
    "    # Amenities -> count\n",
    "    if 'amenities' in df.columns:\n",
    "        df['amenities_count'] = df['amenities'].apply(count_amenities)\n",
    "        df.drop(columns=['amenities'], inplace=True)\n",
    "\n",
    "    # Fill missing reviews_per_month -> 0\n",
    "    if 'reviews_per_month' in df.columns:\n",
    "        df['reviews_per_month'].fillna(0, inplace=True)\n",
    "\n",
    "    # Basic fill for other common fields if missing\n",
    "    fill_zero_cols = ['number_of_reviews', 'minimum_nights', 'calculated_host_listings_count', 'availability_365']\n",
    "    for c in fill_zero_cols:\n",
    "        if c in df.columns:\n",
    "            df[c].fillna(0, inplace=True)\n",
    "\n",
    "    # Create log transforms for skewed columns\n",
    "    df['price_log'] = np.log1p(df['price'])\n",
    "    df['reviews_log'] = np.log1p(df['number_of_reviews']) if 'number_of_reviews' in df.columns else 0\n",
    "    df['nights_log'] = np.log1p(df['minimum_nights']) if 'minimum_nights' in df.columns else 0\n",
    "\n",
    "    # Convert boolean columns to int if any\n",
    "    bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "    if len(bool_cols) > 0:\n",
    "        df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "    # Keep features we will likely use\n",
    "    # We'll choose a pragmatic set: neighbourhood_group, room_type, latitude, longitude,\n",
    "    # calculated_host_listings_count, availability_365, amenities_count, reviews_log, nights_log\n",
    "    selected_cols = [\n",
    "        'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "        'calculated_host_listings_count', 'availability_365',\n",
    "        'amenities_count', 'reviews_log', 'nights_log', 'price_log'\n",
    "    ]\n",
    "    # Ensure selected cols exist; if not, adapt to what's available\n",
    "    present_cols = [c for c in selected_cols if c in df.columns]\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    return df, present_cols\n",
    "\n",
    "# -------------------------\n",
    "# Prepare features for ML (one-hot encode categorical + scaling)\n",
    "# -------------------------\n",
    "def prepare_features(df, feature_cols, fit_meta=None):\n",
    "    \"\"\"\n",
    "    feature_cols: list of columns we will use (must include price_log not here)\n",
    "    fit_meta: if provided, must contain 'columns' list used for reindexing and 'scaler'\n",
    "    returns X (DataFrame), meta dict\n",
    "    \"\"\"\n",
    "    df_local = df.copy()\n",
    "    categorical = [c for c in ['neighbourhood_group', 'room_type'] if c in df_local.columns and c in feature_cols]\n",
    "    numeric = [c for c in feature_cols if c not in categorical]\n",
    "\n",
    "    # One-hot\n",
    "    if categorical:\n",
    "        df_o = pd.get_dummies(df_local[categorical], drop_first=True)\n",
    "        df_local = pd.concat([df_local[numeric], df_o], axis=1)\n",
    "    else:\n",
    "        df_local = df_local[numeric]\n",
    "\n",
    "    # Order columns consistently\n",
    "    if fit_meta is None:\n",
    "        cols = list(df_local.columns)\n",
    "    else:\n",
    "        # Reindex to match training columns, add missing cols as zeros\n",
    "        cols = fit_meta['columns']\n",
    "        df_local = df_local.reindex(columns=cols, fill_value=0)\n",
    "\n",
    "    # Scaling: we can scale for models that benefit - XGBoost doesn't require scaling,\n",
    "    # but scaling is harmless if we save the scaler and apply consistently. We will NOT scale by default\n",
    "    meta = {}\n",
    "    meta['columns'] = list(df_local.columns)\n",
    "    return df_local, meta\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    print(\"Loading and cleaning data...\")\n",
    "    df, present_cols = load_and_clean(DATA_IN)\n",
    "\n",
    "    # select features for training (exclude the target price_log)\n",
    "    # We prefer these features if present:\n",
    "    want = ['neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "            'calculated_host_listings_count', 'availability_365',\n",
    "            'amenities_count', 'reviews_log', 'nights_log']\n",
    "    feature_cols = [c for c in want if c in df.columns]\n",
    "\n",
    "    print(\"Features used:\", feature_cols)\n",
    "\n",
    "    # Prepare features (fit)\n",
    "    X_df, meta = prepare_features(df, feature_cols, fit_meta=None)\n",
    "    y = df['price_log']\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    print(f\"Training rows: {X_train.shape[0]}, Test rows: {X_test.shape[0]}\")\n",
    "\n",
    "    # Train XGBoost\n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create final export DataFrame: add predicted price and price difference\n",
    "    print(\"Creating final export CSV with predictions...\")\n",
    "    # Ensure X_df columns used in training (meta['columns'])\n",
    "    X_for_pred = X_df[meta['columns']]\n",
    "\n",
    "    preds_log = xgb.predict(X_for_pred)\n",
    "    preds_price = np.expm1(preds_log)\n",
    "\n",
    "    df_export = df.copy()\n",
    "    # revert transformed fields to original-ish values for readability\n",
    "    df_export['price'] = np.expm1(df_export['price_log'])\n",
    "    df_export['reviews'] = np.expm1(df_export['reviews_log'])\n",
    "    df_export['nights'] = np.expm1(df_export['nights_log'])\n",
    "\n",
    "    df_export['Predicted_Price'] = preds_price\n",
    "    df_export['Price_Suggestion_Diff'] = df_export['Predicted_Price'] - df_export['price']\n",
    "\n",
    "    # Save CSV\n",
    "    df_export.to_csv(OUT_FINAL, index=False)\n",
    "    print(f\"Wrote final dataset to {OUT_FINAL} ({df_export.shape[0]} rows)\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Create prediction grid for Power BI slider\n",
    "    # -------------------------\n",
    "    print(\"Creating prediction grid for Power BI (slider)...\")\n",
    "    # Choose variables to expose in slider: room_type, neighbourhood_group, minimum_nights, amenities_count\n",
    "    # Use values from the cleaned df to limit cardinality\n",
    "    room_types = df['room_type'].dropna().unique().tolist() if 'room_type' in df.columns else ['home/apt']\n",
    "    neighbourhoods = df['neighbourhood_group'].dropna().unique().tolist() if 'neighbourhood_group' in df.columns else ['Manhattan']\n",
    "\n",
    "    # reasonable ranges:\n",
    "    min_nights_vals = list(range(1, 31))  # 1..30\n",
    "    amenities_vals = list(range(0, max(31, int(df['amenities_count'].max() + 1))))  # 0..max\n",
    "\n",
    "    # To avoid an enormous grid, limit combinations: we will create full cross-product of these\n",
    "    combos = list(itertools.product(room_types, neighbourhoods, min_nights_vals, amenities_vals))\n",
    "    print(f\"Grid will have {len(combos):,} rows (room_type * neighbourhood * min_nights * amenities_count)\")\n",
    "\n",
    "    grid_df = pd.DataFrame(combos, columns=['room_type', 'neighbourhood_group', 'minimum_nights', 'amenities_count'])\n",
    "\n",
    "    # Add other numeric columns with reasonable default values / medians\n",
    "    # Use median values from training df for features not in the grid\n",
    "    medians = {}\n",
    "    for c in ['latitude', 'longitude', 'calculated_host_listings_count', 'availability_365', 'reviews_log', 'nights_log']:\n",
    "        medians[c] = df[c].median() if c in df.columns else 0\n",
    "\n",
    "    # Add columns used by model: latitude/longitude etc.\n",
    "    for c, v in medians.items():\n",
    "        grid_df[c] = v\n",
    "\n",
    "    # For minimum_nights and reviews fields we want to ensure their transformed versions are aligned\n",
    "    # We included 'nights_log' as a feature for training. The grid includes minimum_nights; we must create nights_log\n",
    "    grid_df['nights_log'] = np.log1p(grid_df['minimum_nights'])\n",
    "    # reviews_log use median (already set)\n",
    "\n",
    "    # Now prepare the grid features the same way we prepared training data:\n",
    "    # We must ensure one-hot columns match training columns (meta['columns'])\n",
    "    # First, create a temporary df in same structure as df used in prepare_features\n",
    "    # We need to include the categorical cols and numeric cols\n",
    "    # Build a df that has all the feature columns before one-hot\n",
    "    pre_grid = pd.DataFrame()\n",
    "    # Copy categorical and numeric raw columns used in the original feature_cols\n",
    "    if 'neighbourhood_group' in feature_cols:\n",
    "        pre_grid['neighbourhood_group'] = grid_df['neighbourhood_group']\n",
    "    if 'room_type' in feature_cols:\n",
    "        pre_grid['room_type'] = grid_df['room_type']\n",
    "    # numeric features\n",
    "    for c in ['latitude', 'longitude', 'calculated_host_listings_count', 'availability_365', 'amenities_count', 'reviews_log', 'nights_log']:\n",
    "        if c in feature_cols:\n",
    "            pre_grid[c] = grid_df[c]\n",
    "\n",
    "    # One-hot encode grid in the same way as training df, and then reindex to meta['columns']\n",
    "    grid_o = pd.get_dummies(pre_grid[[c for c in ['neighbourhood_group', 'room_type'] if c in pre_grid.columns]], drop_first=True) if any([c in pre_grid.columns for c in ['neighbourhood_group','room_type']]) else pd.DataFrame(index=pre_grid.index)\n",
    "    numeric_grid = pre_grid[[c for c in pre_grid.columns if c not in ['neighbourhood_group', 'room_type']]]\n",
    "    grid_features = pd.concat([numeric_grid.reset_index(drop=True), grid_o.reset_index(drop=True)], axis=1)\n",
    "    # Reindex to training columns\n",
    "    training_cols = meta['columns']\n",
    "    grid_features = grid_features.reindex(columns=training_cols, fill_value=0)\n",
    "\n",
    "    # Predict on grid\n",
    "    grid_preds_log = xgb.predict(grid_features)\n",
    "    grid_preds_price = np.expm1(grid_preds_log)\n",
    "    grid_df['predicted_price'] = grid_preds_price\n",
    "\n",
    "    # Save grid\n",
    "    grid_df.to_csv(OUT_GRID, index=False)\n",
    "    print(f\"Wrote prediction grid to {OUT_GRID} ({grid_df.shape[0]} rows)\")\n",
    "\n",
    "    print(\"All done. Files created:\")\n",
    "    print(\" -\", OUT_FINAL)\n",
    "    print(\" -\", OUT_GRID)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d2d61-993d-4b65-bf4f-9cae7ac4c953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:another_env_1] *",
   "language": "python",
   "name": "conda-env-another_env_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
